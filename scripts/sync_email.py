import imaplib
import email
from email.header import decode_header
import os
import argparse
import time
import subprocess
from datetime import datetime
import re

# Configuration
IMAP_SERVER = "imap.gmail.com"
EMAIL_ACCOUNT = os.getenv("GMAIL_ACCOUNT")
APP_PASSWORD = os.getenv("GMAIL_APP_PASSWORD")
LOCAL_DIARY_DIR = "diary"
BLOG_DRAFTS_DIR = "blog_drafts"
ANALYSIS_SCRIPT = "scripts/llm_graph_builder.py"
BLOG_WRITER_SCRIPT = "scripts/blog_writer.py"
SUBJECT_KEYWORD = "POMERA" # POMERAã¾ãŸã¯POMERAtoKNOWLEDGEã‚’å«ã‚€ä»¶å
ROLE_KEYWORD = "ROLEtoKNOWLEDGE" # å½¹å‰²å®šç¾©ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
BLOG_KEYWORD = "BLOG"  # ãƒ–ãƒ­ã‚°è‰æ¡ˆç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
ROLE_DEF_FILE = "role_definition.txt"
HISTORY_FILE = "sync_history.txt"

def clean_filename(subject):
    """Converts email subject to a safe filename."""
    # Decode header if needed
    decoded_fragments = decode_header(subject)
    subject_str = ""
    for frag, encoding in decoded_fragments:
        if isinstance(frag, bytes):
            subject_str += frag.decode(encoding or "utf-8")
        else:
            subject_str += frag
            
    # Remove unsafe chars
    safe_name = re.sub(r'[\\/*?:"<>|]', "", subject_str)
    return safe_name.strip()

def get_body_content(msg):
    """Extracts text content from email body."""
    if msg.is_multipart():
        for part in msg.walk():
            content_type = part.get_content_type()
            content_disposition = part.get("Content-Disposition") or ""
            
            if content_type == "text/plain" and "attachment" not in content_disposition:
                try:
                    return part.get_payload(decode=True).decode()
                except:
                    pass
    else:
        try:
            return msg.get_payload(decode=True).decode()
        except:
            pass
    return None

def save_attachment(part, directory):
    """Saves an attachment to the directory."""
    filename = part.get_filename()
    if filename:
        filename = clean_filename(filename)
        filepath = os.path.join(directory, filename)
        
        if os.path.exists(filepath):
            print(f"      âš ï¸  File exists, overwriting: {os.path.basename(filepath)}")
            
        with open(filepath, "wb") as f:
            f.write(part.get_payload(decode=True))
        return filepath
    return None

def connect_imap():
    if not EMAIL_ACCOUNT or not APP_PASSWORD:
        print("âŒ Error: GMAIL_ACCOUNT or GMAIL_APP_PASSWORD not set.")
        return None
    
    try:
        imaplib.IMAP4_SSL.timeout = 30  # 30ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        mail = imaplib.IMAP4_SSL(IMAP_SERVER, timeout=30)
        mail.login(EMAIL_ACCOUNT, APP_PASSWORD)
        return mail
    except Exception as e:
        print(f"âŒ Connection Error: {e}")
        return None

def check_emails(mail, save_dir):
    # Load history
    history = set()
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r") as f:
            history = set(line.strip() for line in f if line.strip())

    # Fetch the latest IDs from the inbox directly
    status, count = mail.select("inbox")
    if status != "OK" or not count[0]:
        return [], []
        
    total_emails = int(count[0])
    print(f"ğŸ“¬ å—ä¿¡ãƒˆãƒ¬ã‚¤ã®ãƒ¡ãƒ¼ãƒ«ç·æ•°: {total_emails}")
    
    # ã¾ãšæœªèª­ãƒ¡ãƒ¼ãƒ«ã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹
    status, data = mail.search(None, 'UNSEEN')
    if status == "OK" and data[0]:
        email_ids = data[0].split()
        print(f"ğŸ“© æœªèª­ãƒ¡ãƒ¼ãƒ« {len(email_ids)} ä»¶ã‚’å‡¦ç†")
    else:
        # æœªèª­ãƒ¡ãƒ¼ãƒ«ãŒãªã‘ã‚Œã°ã€ç›´è¿‘50ä»¶ã‚’FETCHã§å–å¾—
        print("ğŸ“­ æœªèª­ãƒ¡ãƒ¼ãƒ«ãªã—ã€‚ç›´è¿‘50ä»¶ã‚’historyãƒ™ãƒ¼ã‚¹ã§ç¢ºèª")
        start_id = max(1, total_emails - 50 + 1)
        email_ids = [str(i).encode() for i in range(start_id, total_emails + 1)]
        
    saved_files = []
    blog_files = []
    new_history = []

    if not email_ids:
        return [], []

    print(f"ğŸ“© æœ€æ–°ã® {len(email_ids)} ä»¶ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")

    for e_id_bytes in email_ids:
        e_id = e_id_bytes.decode()
        
        # Get UID for persistent tracking
        status, data = mail.fetch(e_id, "(UID)")
        if not data or not data[0]: continue
        
        uid_match = re.search(r'UID (\d+)', data[0].decode())
        if not uid_match:
            continue
        uid = uid_match.group(1)
        
        if uid in history:
            continue

        # Fetch subject
        status, msg_header = mail.fetch(e_id, "(BODY.PEEK[HEADER.FIELDS (SUBJECT)])")
        subject_matched = False
        is_role_definition = False
        is_blog_draft = False
        subject = ""
        
        for response_part in msg_header:
            if isinstance(response_part, tuple):
                msg = email.message_from_bytes(response_part[1])
                raw_subject = msg["Subject"]
                if raw_subject:
                    subject = clean_filename(raw_subject)
                    
                    # ROLEtoKNOWLEDGE ã‚’å…ˆã«åˆ¤å®šã™ã‚‹
                    if ROLE_KEYWORD.lower() in subject.lower():
                        subject_matched = True
                        is_role_definition = True
                    # BLOG ã‚’åˆ¤å®šï¼ˆPOMERAã‚ˆã‚Šå„ªå…ˆï¼‰
                    elif BLOG_KEYWORD.lower() in subject.lower():
                        subject_matched = True
                        is_blog_draft = True
                    elif SUBJECT_KEYWORD.lower() in subject.lower():
                        subject_matched = True
        
        if not subject_matched:
            continue

        print(f"ğŸ‘‰ Processing Email: {subject} (RoleDef: {is_role_definition}, Blog: {is_blog_draft})")
        
        status, msg_data = mail.fetch(e_id, "(RFC822)")
        for response_part in msg_data:
            if isinstance(response_part, tuple):
                msg = email.message_from_bytes(response_part[1])
                
                # --- ROLE DEFINITION HANDLING ---
                if is_role_definition:
                    body = get_body_content(msg)
                    if body:
                        with open(ROLE_DEF_FILE, "w", encoding="utf-8") as f:
                            f.write(body)
                        print(f"      âœ… Role Definition Updated: {ROLE_DEF_FILE}")
                    else:
                        print("      âš ï¸ Role definition email had no body.")
                
                # --- BLOG DRAFT HANDLING ---
                elif is_blog_draft:
                    body = get_body_content(msg)
                    if body:
                        blog_dir = BLOG_DRAFTS_DIR
                        if not os.path.exists(blog_dir):
                            os.makedirs(blog_dir)
                        filename = f"{datetime.now().strftime('%Y%m%d')}_{subject}.txt"
                        filepath = os.path.join(blog_dir, filename)
                        with open(filepath, "w", encoding="utf-8") as f:
                            f.write(body)
                        blog_files.append(filepath)
                        print(f"      ğŸ“ Saved Blog Draft: {filename}")
                        # å‡¦ç†æ¸ˆã¿ãƒ¡ãƒ¼ãƒ«ã‚’æ—¢èª­ã«ã™ã‚‹
                        mail.store(e_id, '+FLAGS', '\\Seen')
                    else:
                        print("      âš ï¸ Blog draft email had no body.")
                    
                # --- POMERA DIARY HANDLING ---
                else:
                    has_attachment = False
                    if msg.is_multipart():
                        for part in msg.walk():
                            if part.get_content_maintype() == 'multipart': continue
                            if part.get('Content-Disposition') is None: continue
                            
                            filename = part.get_filename()
                            if filename and filename.lower().endswith(".txt"):
                                saved_path = save_attachment(part, save_dir)
                                if saved_path:
                                    saved_files.append(saved_path)
                                    has_attachment = True
                                    print(f"      ğŸ“ Saved Attachment: {os.path.basename(saved_path)}")

                    if not has_attachment:
                        body = get_body_content(msg)
                        if body:
                            filename = f"{datetime.now().strftime('%Y%m%d')}_{subject}.txt"
                            filepath = os.path.join(save_dir, filename)
                            with open(filepath, "w", encoding="utf-8") as f:
                                f.write(body)
                            saved_files.append(filepath)
                            print(f"      ğŸ“ Saved Body: {filename}")
        
        new_history.append(uid)

    if new_history:
        with open(HISTORY_FILE, "a") as f:
            for uid in new_history:
                f.write(f"{uid}\n")

    # åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã«ä¸Šæ›¸ãä¿å­˜ã•ã‚ŒãŸé‡è¤‡ã‚’é™¤å»
    unique_files = list(dict.fromkeys(saved_files))
    if len(unique_files) < len(saved_files):
        print(f"âš ï¸ é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å»: {len(saved_files)} â†’ {len(unique_files)} ä»¶")
    unique_blog_files = list(dict.fromkeys(blog_files))
    return unique_files, unique_blog_files

def run_analysis(files):
    if not files: return
    print(f"ğŸš€ LLMåˆ†æã‚’é–‹å§‹ã—ã¾ã™ ({len(files)} ä»¶)...")
    
    for i, file_path in enumerate(files, 1):
        print(f"   [{i}/{len(files)}] Analyzing: {file_path}")
        cmd = ["python3", ANALYSIS_SCRIPT, file_path]
        result = subprocess.run(cmd)
        if result.returncode != 0:
            print(f"   âš ï¸ åˆ†æå¤±æ•—: {file_path} (returncode={result.returncode})")
        # API ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆå¯¾ç­–: é€£ç¶šå‘¼ã³å‡ºã—ã®é–“ã«å°‘ã—å¾…ã¤
        if i < len(files):
            time.sleep(5)


def run_blog_pipeline(blog_files):
    """ãƒ–ãƒ­ã‚°è‰æ¡ˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ç”Ÿæˆã—ã€ã¯ã¦ãªãƒ–ãƒ­ã‚°ã«æŠ•ç¨¿ã™ã‚‹ã€‚"""
    if not blog_files: return
    print(f"ğŸ“ ãƒ–ãƒ­ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹å§‹ã—ã¾ã™ ({len(blog_files)} ä»¶)...")
    
    for i, file_path in enumerate(blog_files, 1):
        print(f"   [{i}/{len(blog_files)}] Processing Blog Draft: {file_path}")
        cmd = ["python3", BLOG_WRITER_SCRIPT, file_path]
        result = subprocess.run(cmd)
        if result.returncode != 0:
            print(f"   âš ï¸ ãƒ–ãƒ­ã‚°è¨˜äº‹ç”Ÿæˆå¤±æ•—: {file_path} (returncode={result.returncode})")
        if i < len(blog_files):
            time.sleep(5)


def main():
    parser = argparse.ArgumentParser(description="Sync Pomera emails and trigger analysis.")
    parser.add_argument("--watch", action="store_true", help="Keep watching for new emails.")
    parser.add_argument("--interval", type=int, default=300, help="Check interval in seconds (default: 300s/5min).")
    parser.add_argument("--blog-only", action="store_true", help="Process only BLOG emails.")
    
    args = parser.parse_args()

    if not os.path.exists(LOCAL_DIARY_DIR):
        os.makedirs(LOCAL_DIARY_DIR)
    if not os.path.exists(BLOG_DRAFTS_DIR):
        os.makedirs(BLOG_DRAFTS_DIR)

    print("ğŸ“§ Pomera & Role & Blog Email Sync Agent Started")
    print(f"   Account: {EMAIL_ACCOUNT}")
    print(f"   Target Dir: {LOCAL_DIARY_DIR}")
    print(f"   Blog Drafts Dir: {BLOG_DRAFTS_DIR}")
    print(f"   Role Definition File: {ROLE_DEF_FILE}")
    print(f"   Blog Only Mode: {args.blog_only}")
    print("   --------------------------------")

    while True:
        mail = connect_imap()
        if mail:
            try:
                new_files, blog_files = check_emails(mail, LOCAL_DIARY_DIR)
                
                if args.blog_only:
                    # BLOGãƒ¢ãƒ¼ãƒ‰: ãƒ–ãƒ­ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã¿å®Ÿè¡Œ
                    if blog_files:
                        run_blog_pipeline(blog_files)
                    else:
                        print("ğŸ’¤ æ–°ç€ã®BLOGãƒ¡ãƒ¼ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                else:
                    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: æ—¥è¨˜åˆ†æ + ãƒ–ãƒ­ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
                    if new_files:
                        run_analysis(new_files)
                    if blog_files:
                        run_blog_pipeline(blog_files)
                    if not new_files and not blog_files:
                        if not args.watch:
                            print("ğŸ’¤ æ–°ç€ã®å¯¾è±¡ãƒ¡ãƒ¼ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                
                mail.logout()
            except Exception as e:
                print(f"âŒ Error during check: {e}")
        
        if not args.watch:
            break
            
        print(f"â³ æ¬¡ã®ãƒã‚§ãƒƒã‚¯ã¾ã§å¾…æ©Ÿä¸­... ({args.interval}ç§’)")
        time.sleep(args.interval)

if __name__ == "__main__":
    main()
