"""
blog_article_writer.py â€” ãƒãƒ¡ãƒ©è‰æ¡ˆ â†’ ãƒ–ãƒ­ã‚°è¨˜äº‹ç”Ÿæˆ

ãƒãƒ¡ãƒ©ã§æ›¸ã„ãŸãƒ¡ãƒ¢ã‚’ã‚‚ã¨ã«ã€Gemini APIã§èª­ã¿ã‚„ã™ã„ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ç”Ÿæˆã™ã‚‹ã€‚
ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‹ã‚‰é–¢é€£ãƒ†ãƒ¼ãƒã‚’å¼•ç”¨ã—ã¦è¨˜äº‹ã«æ·±ã¿ã‚’æŒãŸã›ã‚‹ã€‚
ç”Ÿæˆå¾Œã€hatena_publisher.py ã‚’å‘¼ã³å‡ºã—ã¦ã¯ã¦ãªãƒ–ãƒ­ã‚°ã«ä¸‹æ›¸ãæŠ•ç¨¿ã™ã‚‹ã€‚
"""

import os
import json
import re
import argparse
import subprocess
from datetime import datetime
import requests
from typing import Dict, Any, Optional, Tuple

# è¨­å®š
API_KEY = os.getenv("GOOGLE_API_KEY")
MASTER_GRAPH_PATH = "knowledge_graph.jsonld"
BLOG_READY_DIR = "blog_ready"
HATENA_PUBLISHER_SCRIPT = "scripts/hatena_publisher.py"
WRITING_STYLE_PATH = "writing_style.md"

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ãƒ–ãƒ­ã‚°è¨˜äº‹ ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

BLOG_SYSTEM_PROMPT = """
# å½¹å‰²
ã‚ãªãŸã¯ç­†è€…æœ¬äººã®ä»£ã‚ã‚Šã«ã€ç­†è€…ãŒæ›¸ã„ãŸãƒ¡ãƒ¢ã‚’ãƒ–ãƒ­ã‚°è¨˜äº‹ã¨ã—ã¦ä»•ä¸Šã’ã‚‹ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒãƒ¡ãƒ©ã§æ›¸ã„ãŸã€Œãƒ¡ãƒ¢ã€ã‚„ã€Œè€ƒãˆãŸã“ã¨ã€ã‚’ã‚‚ã¨ã«è¨˜äº‹ã‚’æ›¸ãã¾ã™ãŒã€
**ç­†è€…ã®æ–‡ä½“ãƒ»è¨€è‘‰ã¥ã‹ã„ãƒ»æ€è€ƒã®æµã‚Œã‚’å¿ å®Ÿã«å†ç¾ã™ã‚‹ã“ã¨**ãŒæœ€å¤§ã®ä½¿å‘½ã§ã™ã€‚

# æœ€é‡è¦ï¼šæ–‡ä½“ã®å†ç¾
å¾Œè¿°ã™ã‚‹ã€Œæ–‡ä½“ã‚¬ã‚¤ãƒ‰ã€ã«å¾“ã„ã€ç­†è€…ã®è¨€è‘‰ã§æ›¸ã„ã¦ãã ã•ã„ã€‚
AIã‚‰ã—ã„è¡¨ç¾ãƒ»ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼çš„ãªæ¯”å–©ãƒ»æ•´ç„¶ã¨ã—ãŸæ§‹æˆã¯é¿ã‘ã¦ãã ã•ã„ã€‚

# è¨˜äº‹ã®ã‚¹ã‚¿ã‚¤ãƒ«
- ã€Œã€œã®ã ã€ã€Œã€œãªã®ã ã€ã€Œã€œãŸã„ã®ã ã€ã§æ–‡ã‚’ç· ã‚ã‚‹ã€‚ã“ã‚ŒãŒç­†è€…ã®èªå°¾ã®åŸºæœ¬
- ã€Œã€œã¨æ€ã£ã¦ã„ã‚‹ã€ã€Œã€œã¨è€ƒãˆã¦ã„ã‚‹ã€ã§è‡ªåˆ†ã®è€ƒãˆã‚’èªã‚‹ã€‚æ–­è¨€ã—ã™ããªã„
- ã€Œãªã‚“ã¨ã„ã†ã‹ã€ã€Œã ã‹ã‚‰ã“ãã€ã€Œãã®ã†ãˆã§ã€ãªã©ã®å£èªçš„ãªç¹‹ãè¨€è‘‰ã‚’ä½¿ã†
- æ€è€ƒãŒæµã‚Œå‡ºã‚‹ã‚ˆã†ã«æ›¸ãã€‚é ­ã®ä¸­ã‚’å®Ÿæ³ä¸­ç¶™ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸
- åŒã˜ã“ã¨ã‚’è¨€ã„æ›ãˆãªãŒã‚‰æ˜ã‚Šä¸‹ã’ã‚‹æ›¸ãæ–¹ãŒãƒªã‚ºãƒ ã‚’ä½œã‚‹
- ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã¯ä½¿ã‚ãªã„

# çµ¶å¯¾ã«ä½¿ã‚ãªã„è¡¨ç¾
- ã€Œã€œã„ã‹ãŒã§ã—ãŸã‹ï¼Ÿã€
- ã€Œã€œã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ã€
- ã€Œã€œã—ã¦ã¿ã¦ã¯ã©ã†ã ã‚ã†ã‹ã€
- ã€Œã€œã—ã¦ãã‚Œã‚‹ã¯ãšã ã€
- ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼çš„ãªæ¯”å–©ï¼ˆä¾‹ï¼šã€Œæƒ…å ±ã®ã‚«ã‚¯ãƒ†ãƒ«çŠ¶æ…‹ã€ã€Œè¶…æœ‰èƒ½ãªç§˜æ›¸ã€ï¼‰
- ã€Œã€œã—ã¦ã»ã—ã„ã€ã§èª­è€…ã«è¨´ãˆã‹ã‘ã‚‹ç· ã‚æ–¹

# è¨˜äº‹ã®æ§‹æˆ
- å°å…¥ï¼šå›°ã£ã¦ã„ãŸã“ã¨ãƒ»æ°—ã¥ã„ãŸã“ã¨ã‹ã‚‰æ­£ç›´ã«å§‹ã‚ã‚‹
- æœ¬è«–ï¼šãªãœãã†æ„Ÿã˜ã‚‹ã‹â†’ã©ã†ã—ãŸã‹â†’ã©ã†è€ƒãˆã‚‹ã‹ã®æµã‚Œã§å±•é–‹ã™ã‚‹
- ã¾ã¨ã‚ï¼šç„¡ç†ã«ã¾ã¨ã‚ãªã„ã€‚æ€è€ƒãŒç€åœ°ã™ã‚‹ã¨ã“ã‚ã§è‡ªç„¶ã«çµ‚ã‚ã‚‹
- è¦‹å‡ºã—ã¯ä½¿ã£ã¦ã‚‚1ã€œ2å€‹ã¾ã§ã€‚ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼åŒ–ã—ãŸè¦‹å‡ºã—ã¯é¿ã‘ã‚‹

# çµ¶å¯¾ã«å®ˆã‚‹ã¹ããƒ«ãƒ¼ãƒ«
1. ãƒ¡ãƒ¢ã®å†…å®¹ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒšã—ãªã„ã€‚å¿…ãšè¨˜äº‹ã¨ã—ã¦å†æ§‹æˆã™ã‚‹
2. å€‹äººã‚’ç‰¹å®šã§ãã‚‹æƒ…å ±ã¯æ›¸ã‹ãªã„ã€‚å›ºæœ‰åè©ã¯å¿…è¦ã«å¿œã˜ã¦ä¸€èˆ¬åŒ–ã™ã‚‹
3. ã€Œä»¥ä¸Šã§ã™ã€ã€Œã„ã‹ãŒã§ã—ãŸã‹ï¼Ÿã€ã®ã‚ˆã†ãªå®šå‹æ–‡ã¯ä½¿ã‚ãªã„
4. SEOã‚’æ„è­˜ã—ã™ããŸä¸è‡ªç„¶ãªæ–‡ç« ã¯é¿ã‘ã‚‹
5. è¨˜äº‹ã®å†’é ­ã«ã‚¿ã‚¤ãƒˆãƒ«ã¯æ›¸ã‹ãªã„

# å‡ºåŠ›å½¢å¼
ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:

{
  "title": "ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ30æ–‡å­—ä»¥å†…ã€ã‚·ãƒ³ãƒ—ãƒ«ã§èª¬æ˜çš„ãªã‚‚ã®ï¼‰",
  "body": "æœ¬æ–‡ï¼ˆã¯ã¦ãªãƒ–ãƒ­ã‚°ç”¨Markdownå½¢å¼ï¼‰",
  "description": "ãƒ¡ã‚¿ãƒ‡ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆ120æ–‡å­—ä»¥å†…ã®è¨˜äº‹æ¦‚è¦ï¼‰",
  "categories": ["ã‚«ãƒ†ã‚´ãƒª1", "ã‚«ãƒ†ã‚´ãƒª2"],
  "estimated_read_time": "â—‹åˆ†"
}

# é‡è¦ãªæ³¨æ„äº‹é …
- è¨˜äº‹ã®é•·ã•ã¯1500ã€œ3000æ–‡å­—ç¨‹åº¦ã€‚ã‚¹ãƒãƒ›ã§èª­ã¿åˆ‡ã‚Œã‚‹é•·ã•
- ã¯ã¦ãªãƒ–ãƒ­ã‚°ã®Markdownå½¢å¼ã«å¾“ã†
- ã‚«ãƒ†ã‚´ãƒªã¯å†…å®¹ã«åˆã£ãŸã‚‚ã®ã‚’2ã€œ3å€‹ææ¡ˆã™ã‚‹

è¨€èª: æ—¥æœ¬èªã€‚
JSONä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚
"""

REVIEW_PROMPT = """
ã‚ãªãŸã¯ãƒ–ãƒ­ã‚°ã®ç·¨é›†è€…ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’èª­ã¿ã€å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚

## é‡è¦ãªå‰æï¼šã“ã®è¨˜äº‹ã®æ–‡ä½“ã«ã¤ã„ã¦
ã“ã®è¨˜äº‹ã¯æ„å›³çš„ã«ç­†è€…å›ºæœ‰ã®æ–‡ä½“ã§æ›¸ã‹ã‚Œã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã®ç‰¹å¾´ã¯å•é¡Œã§ã¯ãªãã€ç­†è€…ã®ã‚¹ã‚¿ã‚¤ãƒ«ã¨ã—ã¦å°Šé‡ã—ã¦ãã ã•ã„:
- ã€Œã€œã®ã ã€ã€Œã€œãªã®ã ã€ã€Œã€œãŸã„ã®ã ã€ã¨ã„ã†èªå°¾
- ã€Œãªã‚“ã¨ã„ã†ã‹ã€ã€Œã ã‹ã‚‰ã“ãã€ãªã©ã®å£èªçš„ãªç¹‹ãè¨€è‘‰
- æ€è€ƒã‚’æµã‚Œã‚‹ã‚ˆã†ã«æ›¸ãã€ã‚„ã‚„é•·ã„æ®µè½
- åŒã˜ã“ã¨ã‚’è¨€ã„æ›ãˆãªãŒã‚‰æ˜ã‚Šä¸‹ã’ã¦ã„ãæ§‹æˆ

## ãƒã‚§ãƒƒã‚¯é …ç›®
ä»¥ä¸‹ã®å„é …ç›®ã«ã¤ã„ã¦ã®ã¿æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚æ–‡ä½“ã¸ã®æŒ‡æ‘˜ã¯ä¸è¦ã§ã™ã€‚

1. **æ§‹æˆ**: å†…å®¹ãŒä½•ã‚’è¨€ã„ãŸã„ã®ã‹ã‚’è¿½ãˆãªã„ç®‡æ‰€ãŒã‚ã‚‹ã‹
2. **å…·ä½“æ€§**: åˆè¦‹ã®èª­è€…ãŒå†…å®¹ã‚’ã¾ã£ãŸãã‚¤ãƒ¡ãƒ¼ã‚¸ã§ããªã„æŠ½è±¡çš„ãªèª¬æ˜ãŒã‚ã‚‹ã‹
3. **ã‚¿ã‚¤ãƒˆãƒ«**: è¨˜äº‹ã®å†…å®¹ã¨å¤§ããã‚ºãƒ¬ã¦ã„ã‚‹ã‹

## å‡ºåŠ›å½¢å¼
ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:

{
  "passed": true/false,
  "issues": [
    {
      "type": "æ§‹æˆ",
      "detail": "å…·ä½“çš„ãªå•é¡Œç®‡æ‰€ã¨ç†ç”±",
      "suggestion": "æ”¹å–„æ¡ˆ"
    }
  ]
}

æ–‡ä½“ã«é–¢ã™ã‚‹æŒ‡æ‘˜ã¯ä¸€åˆ‡ã—ãªã„ã§ãã ã•ã„ã€‚
å•é¡ŒãŒãªã‘ã‚Œã° passed ã‚’ true ã«ã—ã€issues ã¯ç©ºé…åˆ—ã«ã—ã¦ãã ã•ã„ã€‚
JSONä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚
"""


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def call_gemini_api(prompt: str, max_retries: int = 3) -> str:
    """Gemini APIã‚’å‘¼ã³å‡ºã™ã€‚"""
    if not API_KEY:
        raise ValueError("GOOGLE_API_KEY is not set.")

    url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent"
    params = {"key": API_KEY}
    headers = {"Content-Type": "application/json"}

    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"response_mime_type": "application/json"}
    }

    for attempt in range(max_retries + 1):
        response = requests.post(url, headers=headers, json=data, params=params)

        if response.status_code == 200:
            break
        elif response.status_code == 429 and attempt < max_retries:
            wait_time = 30 * (2 ** attempt)
            print(f"â³ ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆåˆ°é”ã€‚{wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™... ({attempt + 1}/{max_retries})")
            import time
            time.sleep(wait_time)
        else:
            raise Exception(f"API Error: {response.status_code} - {response.text}")

    result = response.json()
    try:
        if "candidates" in result and result["candidates"]:
            return result["candidates"][0]["content"]["parts"][0]["text"]
        else:
            raise Exception(f"Empty candidates in response: {result}")
    except (KeyError, IndexError):
        raise Exception(f"Unexpected API response format: {result}")


def load_writing_style() -> str:
    """æ–‡ä½“ã‚¬ã‚¤ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚"""
    if not os.path.exists(WRITING_STYLE_PATH):
        print("âš ï¸ æ–‡ä½“ã‚¬ã‚¤ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ–‡ä½“æŒ‡ç¤ºã§ç”Ÿæˆã—ã¾ã™ã€‚")
        return ""

    try:
        with open(WRITING_STYLE_PATH, "r", encoding="utf-8") as f:
            content = f.read()
        print("âœï¸ æ–‡ä½“ã‚¬ã‚¤ãƒ‰ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        return content
    except Exception as e:
        print(f"âš ï¸ æ–‡ä½“ã‚¬ã‚¤ãƒ‰ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        return ""


def load_knowledge_graph() -> Optional[Dict[str, Any]]:
    """ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‚’èª­ã¿è¾¼ã‚€ã€‚"""
    if not os.path.exists(MASTER_GRAPH_PATH):
        print("âš ï¸ ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è‰æ¡ˆã®ã¿ã§è¨˜äº‹ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
        return None
    
    try:
        with open(MASTER_GRAPH_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        return None


def extract_blog_context(graph: Dict[str, Any]) -> str:
    """ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‹ã‚‰ãƒ–ãƒ­ã‚°è¨˜äº‹ã«å½¹ç«‹ã¤ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹ã€‚

    æœ€è¿‘ã®çŸ¥è¦‹ãƒ»æ„Ÿæƒ…ãƒ»ã‚¿ã‚¹ã‚¯ã®å‚¾å‘ã‹ã‚‰ã€è¨˜äº‹ã®åˆ‡ã‚Šå£ã«ä½¿ãˆã‚‹æƒ…å ±ã‚’æä¾›ã™ã‚‹ã€‚
    """
    nodes = graph.get("nodes", [])
    
    # çŸ¥è¦‹ã‹ã‚‰ãƒ†ãƒ¼ãƒã‚’æŠ½å‡º
    insights = [n for n in nodes if n.get("type") == "çŸ¥è¦‹"]
    insights_sorted = sorted(insights, key=lambda x: x.get("last_seen", ""), reverse=True)[:8]
    
    # æ„Ÿæƒ…ã®å‚¾å‘ã‚’æŠ½å‡º
    emotions = [n for n in nodes if n.get("type") == "æ„Ÿæƒ…"]
    emotions_sorted = sorted(emotions, key=lambda x: x.get("last_seen", ""), reverse=True)[:5]
    
    # ã‚¿ã‚¹ã‚¯ã®å‚¾å‘ã‚’æŠ½å‡º
    tasks = [n for n in nodes if n.get("type") == "ã‚¿ã‚¹ã‚¯"]
    tasks_sorted = sorted(tasks, key=lambda x: x.get("last_seen", ""), reverse=True)[:5]
    
    context = "### ç­†è€…ã®æœ€è¿‘ã®é–¢å¿ƒäº‹ï¼ˆè¨˜äº‹ã«æ·±ã¿ã‚’æŒãŸã›ã‚‹ãŸã‚ã®èƒŒæ™¯æƒ…å ±ï¼‰\n"
    
    if insights_sorted:
        context += "\n**æœ€è¿‘ã®æ°—ã¥ã:**\n"
        for i in insights_sorted:
            label = i.get('label', '')
            detail = i.get('detail', '')
            if detail:
                context += f"- {label}: {detail[:80]}\n"
            else:
                context += f"- {label}\n"
    
    if emotions_sorted:
        context += "\n**æœ€è¿‘ã®æ„Ÿæƒ…å‚¾å‘:**\n"
        for e in emotions_sorted:
            label = e.get('label', '')
            sentiment = e.get('sentiment', 0)
            tone = "ãƒã‚¸ãƒ†ã‚£ãƒ–" if sentiment > 0 else "ãƒã‚¬ãƒ†ã‚£ãƒ–" if sentiment < 0 else "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«"
            context += f"- {label}ï¼ˆ{tone}ï¼‰\n"
    
    if tasks_sorted:
        context += "\n**æœ€è¿‘å–ã‚Šçµ„ã‚“ã§ã„ã‚‹ã“ã¨:**\n"
        for t in tasks_sorted:
            label = t.get('label', '')
            context += f"- {label}\n"
    
    return context


def parse_blog_memo(memo_text: str) -> Dict[str, str]:
    """ãƒ–ãƒ­ã‚°ç”¨ãƒ¡ãƒ¢ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ã€‚

    ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå½¢å¼ã«ã‚‚è‡ªç”±å½¢å¼ã«ã‚‚å¯¾å¿œã™ã‚‹ã€‚
    ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:
    - ãƒ†ãƒ¼ãƒ
    - ã‚«ãƒ†ã‚´ãƒª
    - ä¼ãˆãŸã„ã“ã¨
    - ãƒ¡ãƒ¢
    """
    fields = {
        "ãƒ†ãƒ¼ãƒ": "",
        "ã‚«ãƒ†ã‚´ãƒª": "",
        "ä¼ãˆãŸã„ã“ã¨": "",
        "ãƒ¡ãƒ¢": ""
    }
    
    known_keys = list(fields.keys())
    has_template = any(f"{key}:" in memo_text or f"{key}ï¼š" in memo_text for key in known_keys[:2])
    
    if not has_template:
        fields["ãƒ¡ãƒ¢"] = memo_text.strip()
        return fields
    
    current_key = None
    current_lines = []
    
    for line in memo_text.split("\n"):
        stripped = line.strip()
        if not stripped:
            if current_key:
                current_lines.append("")
            continue
        
        matched_key = None
        for key in known_keys:
            if stripped.startswith(f"{key}:") or stripped.startswith(f"{key}ï¼š"):
                matched_key = key
                break
        
        if matched_key:
            if current_key:
                fields[current_key] = "\n".join(current_lines).strip()
            current_key = matched_key
            sep = "ï¼š" if f"{matched_key}ï¼š" in stripped else ":"
            value = stripped.split(sep, 1)[1].strip()
            current_lines = [value] if value else []
        else:
            current_lines.append(stripped)
    
    if current_key:
        fields[current_key] = "\n".join(current_lines).strip()
    
    return fields


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def build_generation_prompt(fields: Dict[str, str], context: str, style_guide: str = "") -> str:
    """ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚"""
    memo_section = "### ãƒ–ãƒ­ã‚°ã®ãƒã‚¿ï¼ˆãƒãƒ¡ãƒ©ã§æ›¸ã„ãŸãƒ¡ãƒ¢ï¼‰\n\n"

    if fields["ãƒ†ãƒ¼ãƒ"]:
        memo_section += f"**ãƒ†ãƒ¼ãƒ:** {fields['ãƒ†ãƒ¼ãƒ']}\n"
    if fields["ã‚«ãƒ†ã‚´ãƒª"]:
        memo_section += f"**ã‚«ãƒ†ã‚´ãƒª:** {fields['ã‚«ãƒ†ã‚´ãƒª']}\n"
    if fields["ä¼ãˆãŸã„ã“ã¨"]:
        memo_section += f"\n**ä¼ãˆãŸã„ã“ã¨:**\n{fields['ä¼ãˆãŸã„ã“ã¨']}\n"
    if fields["ãƒ¡ãƒ¢"]:
        memo_section += f"\n**ãƒ¡ãƒ¢ã®å†…å®¹:**\n{fields['ãƒ¡ãƒ¢']}\n"

    style_section = ""
    if style_guide:
        style_section = f"""
### æ–‡ä½“ã‚¬ã‚¤ãƒ‰ï¼ˆæœ€å„ªå…ˆã§å¾“ã†ã“ã¨ï¼‰
{style_guide}
"""

    return f"""
{BLOG_SYSTEM_PROMPT}
{style_section}
{context}

{memo_section}

### æŒ‡ç¤º
ä¸Šè¨˜ã®ãƒ¡ãƒ¢ã‚’ã‚‚ã¨ã«ã€æ–‡ä½“ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ãŸç­†è€…ã®è¨€è‘‰ã§ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’1æœ¬åŸ·ç­†ã—ã¦ãã ã•ã„ã€‚
ãƒ¡ãƒ¢ã®å†…å®¹ã‚’ãã®ã¾ã¾ä½¿ã†ã®ã§ã¯ãªãã€ãƒ–ãƒ­ã‚°è¨˜äº‹ã¨ã—ã¦å†æ§‹æˆã—ã¦ãã ã•ã„ã€‚
èƒŒæ™¯æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯ã€è¨˜äº‹ã«æ·±ã¿ã‚’æŒãŸã›ã‚‹ãŸã‚ã«æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚
"""


def review_article(article_body: str) -> Tuple[bool, list]:
    """ç”Ÿæˆã•ã‚ŒãŸãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ã€‚"""
    prompt = f"""
{REVIEW_PROMPT}

### ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ã®ãƒ–ãƒ­ã‚°è¨˜äº‹
{article_body}
"""
    
    print("ğŸ” å“è³ªãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­...")
    json_text = call_gemini_api(prompt)
    result = json.loads(json_text)
    passed = result.get("passed", True)
    issues = result.get("issues", [])
    
    if issues:
        for issue in issues:
            print(f"   âš ï¸ [{issue.get('type', 'ä¸æ˜')}] {issue.get('detail', '')}")
    else:
        print("   âœ… å“è³ªãƒã‚§ãƒƒã‚¯åˆæ ¼")
    
    return passed, issues


def generate_blog_article(memo_text: str, context: str, style_guide: str = "", max_revisions: int = 1) -> Dict[str, Any]:
    """ãƒ¡ãƒ¢ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ç”Ÿæˆã™ã‚‹ã€‚

    ç”Ÿæˆå¾Œã«è‡ªå·±ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã„ã€å“è³ªã«å•é¡ŒãŒã‚ã‚Œã°
    ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åæ˜ ã—ã¦å†ç”Ÿæˆã™ã‚‹ã€‚
    """

    fields = parse_blog_memo(memo_text)

    prompt = build_generation_prompt(fields, context, style_guide)
    print("ğŸ“ ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ç”Ÿæˆä¸­...")
    json_text = call_gemini_api(prompt)
    article_data = json.loads(json_text)

    for revision in range(max_revisions):
        article_body = article_data.get("body", "")
        if not article_body:
            break

        passed, issues = review_article(article_body)

        if passed:
            break

        feedback_lines = []
        for issue in issues:
            feedback_lines.append(
                f"- [{issue.get('type', '')}] {issue.get('detail', '')}\n"
                f"  æ”¹å–„æ¡ˆ: {issue.get('suggestion', '')}"
            )
        feedback_section = "\n".join(feedback_lines)

        revision_prompt = f"""
{BLOG_SYSTEM_PROMPT}

{context}

{build_generation_prompt(fields, context, style_guide)}

### å‰å›ã®ç”Ÿæˆçµæœã«å¯¾ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
ä»¥ä¸‹ã®å•é¡ŒãŒæŒ‡æ‘˜ã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã‚’å…¨ã¦ä¿®æ­£ã—ãŸä¸Šã§ã€è¨˜äº‹ã‚’æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚
æ–‡ä½“ã‚¬ã‚¤ãƒ‰ã®æŒ‡ç¤ºã‚‚å†ç¢ºèªã—ã€ç­†è€…ã®æ–‡ä½“ã‹ã‚‰ã‚¢ã®ç«‹ã£ãŸè¡¨ç¾ã«ãªã£ã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚

{feedback_section}

### å‰å›ã®æœ¬æ–‡ï¼ˆå‚è€ƒï¼‰
{article_body[:1000]}...

### æŒ‡ç¤º
ä¸Šè¨˜ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åæ˜ ã—ã€å•é¡Œã‚’ä¿®æ­£ã—ãŸæ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’åŸ·ç­†ã—ã¦ãã ã•ã„ã€‚
è¨˜äº‹ã®éª¨æ ¼ã¯ç¶­æŒã—ã¤ã¤ã€æŒ‡æ‘˜ã•ã‚ŒãŸå“è³ªå•é¡Œã‚’è§£æ¶ˆã—ã¦ãã ã•ã„ã€‚
"""

        print(f"ğŸ“ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åæ˜ ç‰ˆã‚’ç”Ÿæˆä¸­... (ãƒªãƒ“ã‚¸ãƒ§ãƒ³ {revision + 1}/{max_revisions})")
        json_text = call_gemini_api(revision_prompt)
        article_data = json.loads(json_text)

    return article_data


def save_article(article_data: Dict[str, Any], source_file: str) -> tuple:
    """ç”Ÿæˆã•ã‚ŒãŸãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ã€‚"""
    if not os.path.exists(BLOG_READY_DIR):
        os.makedirs(BLOG_READY_DIR)
    
    date_str = datetime.now().strftime('%Y%m%d')
    title = article_data.get("title", "ç„¡é¡Œ")
    
    safe_title = re.sub(r'[\\/*?:"<>|]', '', title)[:50]
    
    md_filename = f"{date_str}_{safe_title}.md"
    md_path = os.path.join(BLOG_READY_DIR, md_filename)
    
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(article_data.get("body", ""))
    
    meta_filename = f"{date_str}_{safe_title}.json"
    meta_path = os.path.join(BLOG_READY_DIR, meta_filename)
    
    meta = {
        "title": title,
        "description": article_data.get("description", ""),
        "categories": article_data.get("categories", []),
        "estimated_read_time": article_data.get("estimated_read_time", ""),
        "source_file": source_file,
        "generated_at": datetime.now().isoformat(),
        "type": "blog_article"
    }
    
    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {md_path}")
    print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {meta_path}")
    
    return md_path, meta_path


def publish_to_hatena(md_path: str, meta_path: str):
    """ã¯ã¦ãªãƒ–ãƒ­ã‚°ã«ä¸‹æ›¸ãæŠ•ç¨¿ã™ã‚‹ã€‚"""
    cmd = ["python3", HATENA_PUBLISHER_SCRIPT, md_path, "--meta", meta_path, "--force"]
    print("ğŸš€ ã¯ã¦ãªãƒ–ãƒ­ã‚°ã¸ã®æŠ•ç¨¿ã‚’é–‹å§‹...")
    result = subprocess.run(cmd)
    if result.returncode != 0:
        print(f"âš ï¸ ã¯ã¦ãªãƒ–ãƒ­ã‚°ã¸ã®æŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ (returncode={result.returncode})")
    else:
        print("âœ… ã¯ã¦ãªãƒ–ãƒ­ã‚°ã¸ã®æŠ•ç¨¿ãŒå®Œäº†ã—ã¾ã—ãŸ")


def main():
    parser = argparse.ArgumentParser(description="ãƒãƒ¡ãƒ©ãƒ¡ãƒ¢ â†’ ãƒ–ãƒ­ã‚°è¨˜äº‹ â†’ ã¯ã¦ãªãƒ–ãƒ­ã‚°æŠ•ç¨¿")
    parser.add_argument("input_file", help="ãƒ¡ãƒ¢ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--skip-publish", action="store_true", help="ã¯ã¦ãªãƒ–ãƒ­ã‚°ã¸ã®æŠ•ç¨¿ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    parser.add_argument("--master-graph", default=MASTER_GRAPH_PATH, help="ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã®ãƒ‘ã‚¹")
    
    args = parser.parse_args()
    
    # 1. ãƒ¡ãƒ¢ã®èª­ã¿è¾¼ã¿
    try:
        import unicodedata
        args.input_file = unicodedata.normalize('NFC', args.input_file)
        with open(args.input_file, "r", encoding="utf-8") as f:
            memo_text = f.read()
    except FileNotFoundError:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.input_file}")
        return
    
    if not memo_text.strip():
        print("âŒ ãƒ¡ãƒ¢ãŒç©ºã§ã™ã€‚")
        return
    
    print(f"ğŸ“„ ãƒ¡ãƒ¢ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {args.input_file}")
    print(f"   æ–‡å­—æ•°: {len(memo_text)}")
    
    # 2. æ–‡ä½“ã‚¬ã‚¤ãƒ‰ã‚’èª­ã¿è¾¼ã‚€
    style_guide = load_writing_style()

    # 3. ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    context = ""
    graph = load_knowledge_graph()
    if graph:
        context = extract_blog_context(graph)
        print("ğŸ“Š ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¾ã—ãŸ")

    # 4. ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ç”Ÿæˆ
    try:
        article_data = generate_blog_article(memo_text, context, style_guide)
        print(f"âœ¨ è¨˜äº‹ç”Ÿæˆå®Œäº†: ã€Œ{article_data.get('title', 'ç„¡é¡Œ')}ã€")
    except Exception as e:
        print(f"âŒ è¨˜äº‹ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # 5. ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    md_path, meta_path = save_article(article_data, args.input_file)

    # 6. ã¯ã¦ãªãƒ–ãƒ­ã‚°ã«æŠ•ç¨¿
    if not args.skip_publish:
        publish_to_hatena(md_path, meta_path)
    else:
        print("â­ï¸ ã¯ã¦ãªãƒ–ãƒ­ã‚°ã¸ã®æŠ•ç¨¿ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ")


if __name__ == "__main__":
    main()
