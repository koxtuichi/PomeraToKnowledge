"""
hatena_publisher.py â€” ã¯ã¦ãªãƒ–ãƒ­ã‚° AtomPub API æŠ•ç¨¿

ç”Ÿæˆã•ã‚ŒãŸãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ã¯ã¦ãªãƒ–ãƒ­ã‚°ã«ä¸‹æ›¸ãã¨ã—ã¦æŠ•ç¨¿ã™ã‚‹ã€‚
WSSEèªè¨¼ã‚’ä½¿ç”¨ã—ã€AtomPub APIã§è¨˜äº‹ã‚’æŠ•ç¨¿ã™ã‚‹ã€‚
"""

import os
import json
import argparse
import hashlib
import base64
import datetime
import random
import string
from typing import Optional
import requests

# è¨­å®š
HATENA_ID = os.getenv("HATENA_ID", "kakikukekoichi")
HATENA_BLOG_ID = os.getenv("HATENA_BLOG_ID", "kakikukekoichi.hatenablog.com")
HATENA_API_KEY = os.getenv("HATENA_API_KEY")
BLOG_PUBLISHED_DIR = "blog_published"


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# WSSEèªè¨¼
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def generate_wsse_header(username: str, api_key: str) -> str:
    """WSSEèªè¨¼ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    nonce = ''.join(random.choices(string.ascii_letters + string.digits, k=40))
    nonce_bytes = nonce.encode('utf-8')
    created = datetime.datetime.now(datetime.timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')
    
    # PasswordDigest = Base64(SHA1(Nonce + Created + Password))
    digest_input = nonce_bytes + created.encode('utf-8') + api_key.encode('utf-8')
    password_digest = base64.b64encode(hashlib.sha1(digest_input).digest()).decode('utf-8')
    nonce_b64 = base64.b64encode(nonce_bytes).decode('utf-8')
    
    return (
        f'UsernameToken Username="{username}", '
        f'PasswordDigest="{password_digest}", '
        f'Nonce="{nonce_b64}", '
        f'Created="{created}"'
    )


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ã¯ã¦ãªãƒ–ãƒ­ã‚°æŠ•ç¨¿
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def create_entry_xml(title: str, content: str, categories: list = None, draft: bool = True) -> str:
    """AtomPubå½¢å¼ã®XMLã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ä½œæˆã™ã‚‹ã€‚"""
    # ã‚«ãƒ†ã‚´ãƒªã‚¿ã‚°ã®ç”Ÿæˆ
    category_xml = ""
    if categories:
        for cat in categories:
            category_xml += f'  <category term="{cat}" />\n'
    
    # ä¸‹æ›¸ããƒ•ãƒ©ã‚°
    draft_value = "yes" if draft else "no"
    
    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®XMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
    content_escaped = (content
        .replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;"))
    
    xml = f"""<?xml version="1.0" encoding="utf-8"?>
<entry xmlns="http://www.w3.org/2005/Atom"
       xmlns:app="http://www.w3.org/2007/app">
  <title>{title}</title>
  <author><name>{HATENA_ID}</name></author>
  <content type="text/x-markdown">{content_escaped}</content>
{category_xml}  <app:control>
    <app:draft>{draft_value}</app:draft>
  </app:control>
</entry>"""
    
    return xml


def post_to_hatena(title: str, content: str, categories: list = None, draft: bool = True) -> Optional[dict]:
    """ã¯ã¦ãªãƒ–ãƒ­ã‚°ã«è¨˜äº‹ã‚’æŠ•ç¨¿ã™ã‚‹ã€‚"""
    if not HATENA_API_KEY:
        print("âŒ HATENA_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("   GitHub Secretsã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã« HATENA_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return None
    
    endpoint = f"https://blog.hatena.ne.jp/{HATENA_ID}/{HATENA_BLOG_ID}/atom/entry"
    
    wsse = generate_wsse_header(HATENA_ID, HATENA_API_KEY)
    headers = {
        "X-WSSE": wsse,
        "Content-Type": "application/xml",
        "Accept": "application/xml"
    }
    
    xml_body = create_entry_xml(title, content, categories, draft)
    
    try:
        response = requests.post(endpoint, headers=headers, data=xml_body.encode('utf-8'))
        
        if response.status_code == 201:
            print(f"âœ… æŠ•ç¨¿æˆåŠŸï¼ ({'ä¸‹æ›¸ã' if draft else 'å…¬é–‹'})")
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰URLã‚’æŠ½å‡º
            entry_url = extract_url_from_response(response.text)
            return {
                "status": "success",
                "draft": draft,
                "url": entry_url,
                "title": title
            }
        else:
            print(f"âŒ æŠ•ç¨¿å¤±æ•—: {response.status_code}")
            print(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.text[:500]}")
            return None
            
    except Exception as e:
        print(f"âŒ æŠ•ç¨¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def extract_url_from_response(xml_text: str) -> str:
    """ãƒ¬ã‚¹ãƒãƒ³ã‚¹XMLã‹ã‚‰è¨˜äº‹URLã‚’æŠ½å‡ºã™ã‚‹ã€‚"""
    import re
    # alternate linkã‚’æ¢ã™
    match = re.search(r'<link rel="alternate"[^>]*href="([^"]+)"', xml_text)
    if match:
        return match.group(1)
    return ""


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# å…¬é–‹å±¥æ­´ç®¡ç†
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def is_already_published(source_file: str) -> bool:
    """åŒã˜ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ—¢ã«æŠ•ç¨¿æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã€‚"""
    history_path = os.path.join(BLOG_PUBLISHED_DIR, "publish_history.json")
    if not os.path.exists(history_path):
        return False
    
    try:
        with open(history_path, "r", encoding="utf-8") as f:
            history = json.load(f)
        return source_file in [h.get("source_file") for h in history]
    except Exception:
        return False


def record_publication(result: dict, source_file: str):
    """æŠ•ç¨¿å±¥æ­´ã‚’è¨˜éŒ²ã™ã‚‹ã€‚"""
    if not os.path.exists(BLOG_PUBLISHED_DIR):
        os.makedirs(BLOG_PUBLISHED_DIR)
    
    history_path = os.path.join(BLOG_PUBLISHED_DIR, "publish_history.json")
    history = []
    
    if os.path.exists(history_path):
        try:
            with open(history_path, "r", encoding="utf-8") as f:
                history = json.load(f)
        except Exception:
            history = []
    
    history.append({
        "title": result.get("title", ""),
        "url": result.get("url", ""),
        "draft": result.get("draft", True),
        "source_file": source_file,
        "published_at": datetime.datetime.now().isoformat()
    })
    
    with open(history_path, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“‹ æŠ•ç¨¿å±¥æ­´ã‚’è¨˜éŒ²ã—ã¾ã—ãŸ: {history_path}")


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def main():
    parser = argparse.ArgumentParser(description="ã¯ã¦ãªãƒ–ãƒ­ã‚°ã«è¨˜äº‹ã‚’æŠ•ç¨¿ã™ã‚‹")
    parser.add_argument("input_file", help="æŠ•ç¨¿ã™ã‚‹Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--meta", help="ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--publish", action="store_true", help="ä¸‹æ›¸ãã§ã¯ãªãå…¬é–‹ã¨ã—ã¦æŠ•ç¨¿")
    parser.add_argument("--force", action="store_true", help="æ—¢ã«æŠ•ç¨¿æ¸ˆã¿ã§ã‚‚å¼·åˆ¶çš„ã«å†æŠ•ç¨¿")
    
    args = parser.parse_args()
    
    # 1. è¨˜äº‹æœ¬æ–‡ã®èª­ã¿è¾¼ã¿
    try:
        with open(args.input_file, "r", encoding="utf-8") as f:
            content = f.read()
    except FileNotFoundError:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.input_file}")
        return
    
    # 2. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    title = "ç„¡é¡Œ"
    categories = []
    source_file = args.input_file
    
    if args.meta:
        try:
            with open(args.meta, "r", encoding="utf-8") as f:
                meta = json.load(f)
            title = meta.get("title", "ç„¡é¡Œ")
            categories = meta.get("categories", [])
            source_file = meta.get("source_file", args.input_file)
        except Exception as e:
            print(f"âš ï¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
    
    # 3. äºŒé‡æŠ•ç¨¿ãƒã‚§ãƒƒã‚¯
    if not args.force and is_already_published(source_file):
        print(f"âš ï¸ ã“ã®è‰æ¡ˆã¯æ—¢ã«æŠ•ç¨¿æ¸ˆã¿ã§ã™: {source_file}")
        print("   å†æŠ•ç¨¿ã™ã‚‹ã«ã¯ --force ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
        return
    
    # 4. æŠ•ç¨¿
    draft = not args.publish
    print(f"ğŸ“ æŠ•ç¨¿æº–å‚™:")
    print(f"   ã‚¿ã‚¤ãƒˆãƒ«: {title}")
    print(f"   ã‚«ãƒ†ã‚´ãƒª: {', '.join(categories) if categories else 'ãªã—'}")
    print(f"   ãƒ¢ãƒ¼ãƒ‰: {'ä¸‹æ›¸ã' if draft else 'å…¬é–‹'}")
    print(f"   æ–‡å­—æ•°: {len(content)}")
    
    result = post_to_hatena(title, content, categories, draft)
    
    if result:
        record_publication(result, source_file)
        if result.get("url"):
            print(f"ğŸ”— è¨˜äº‹URL: {result['url']}")


if __name__ == "__main__":
    main()
